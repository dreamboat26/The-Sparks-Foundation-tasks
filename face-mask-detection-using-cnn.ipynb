{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1176415,"sourceType":"datasetVersion","datasetId":667889}],"dockerImageVersionId":30260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport xml.etree.ElementTree as ET\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\n\ninput_data_path = '/kaggle/input/face-mask-detection/images'\nannotations_path = \"/kaggle/input/face-mask-detection/annotations\"\nimages = [*os.listdir(\"/kaggle/input/face-mask-detection/images\")]\noutput_data_path = '.'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-07T16:15:03.974420Z","iopub.execute_input":"2024-08-07T16:15:03.975476Z","iopub.status.idle":"2024-08-07T16:15:11.027937Z","shell.execute_reply.started":"2024-08-07T16:15:03.975383Z","shell.execute_reply":"2024-08-07T16:15:11.026812Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def parse_annotation_object(annotation_object):\n    params = {}\n    for param in list(annotation_object):\n        if param.tag == 'name':\n            params['name'] = param.text\n        if param.tag == 'bndbox':\n            for coord in list(param):\n                params[coord.tag] = int(coord.text)\n    return params","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:16:36.884535Z","iopub.execute_input":"2024-08-07T16:16:36.885880Z","iopub.status.idle":"2024-08-07T16:16:36.892211Z","shell.execute_reply.started":"2024-08-07T16:16:36.885836Z","shell.execute_reply":"2024-08-07T16:16:36.891128Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = []\nfor anno in glob.glob(annotations_path + \"/*.xml\"):\n    tree = ET.parse(anno)\n    root = tree.getroot()\n    constants = {'file': root.find('filename').text[0:-4]}\n    objects = root.findall('object')\n    for obj in objects:\n        object_params = parse_annotation_object(obj)\n        dataset.append({**constants, **object_params})\n\ndf = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:16:41.778663Z","iopub.execute_input":"2024-08-07T16:16:41.779101Z","iopub.status.idle":"2024-08-07T16:16:46.674706Z","shell.execute_reply.started":"2024-08-07T16:16:41.779050Z","shell.execute_reply":"2024-08-07T16:16:46.673759Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"final_test_image = 'maksssksksss0'\nimages.remove(f'{final_test_image}.png')\ndf = df[df[\"file\"] != final_test_image]","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:16:55.010413Z","iopub.execute_input":"2024-08-07T16:16:55.010857Z","iopub.status.idle":"2024-08-07T16:16:55.025494Z","shell.execute_reply.started":"2024-08-07T16:16:55.010822Z","shell.execute_reply":"2024-08-07T16:16:55.024202Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:17:06.030319Z","iopub.execute_input":"2024-08-07T16:17:06.031294Z","iopub.status.idle":"2024-08-07T16:17:06.041954Z","shell.execute_reply.started":"2024-08-07T16:17:06.031242Z","shell.execute_reply":"2024-08-07T16:17:06.040821Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for label in df['name'].unique():\n    for d in ['train', 'test', 'val']:\n        path = os.path.join(output_data_path, d, label)\n        os.makedirs(path, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:17:11.580142Z","iopub.execute_input":"2024-08-07T16:17:11.580997Z","iopub.status.idle":"2024-08-07T16:17:11.591128Z","shell.execute_reply.started":"2024-08-07T16:17:11.580956Z","shell.execute_reply":"2024-08-07T16:17:11.589850Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def crop_img(image_path, x_min, y_min, x_max, y_max):\n    img = Image.open(image_path)\n    cropped = img.crop((x_min - (x_max - x_min) * 0.1, y_min - (y_max - y_min) * 0.1, x_max + (x_max - x_min) * 0.1, y_max + (y_max - y_min) * 0.1))\n    return cropped\n\ndef save_image(image, image_name, dataset_type, label):\n    output_path = os.path.join(output_data_path, dataset_type, label, f'{image_name}.png')\n    image.save(output_path)\n\nfor dataset, dataset_type in [(train_df, 'train'), (test_df, 'test'), (val_df, 'val')]:\n    for _, row in dataset.iterrows():\n        image_path = os.path.join(input_data_path, row['file'] + '.png')\n        image = crop_img(image_path, row['xmin'], row['ymin'], row['xmax'], row['ymax'])\n        save_image(image, row['file'] + '_' + str((row['xmin'], row['ymin'])), dataset_type, row['name'])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:17:16.048880Z","iopub.execute_input":"2024-08-07T16:17:16.049325Z","iopub.status.idle":"2024-08-07T16:18:38.160017Z","shell.execute_reply.started":"2024-08-07T16:17:16.049288Z","shell.execute_reply":"2024-08-07T16:18:38.158819Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(35, 35, 3)),\n    MaxPooling2D(pool_size=2),\n    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n    MaxPooling2D(pool_size=2),\n    Dropout(0.3),\n    Flatten(),\n    Dense(units=500, activation='relu'),\n    Dropout(0.2),\n    Dense(units=3, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:20:05.599894Z","iopub.execute_input":"2024-08-07T16:20:05.600959Z","iopub.status.idle":"2024-08-07T16:20:09.173707Z","shell.execute_reply.started":"2024-08-07T16:20:05.600918Z","shell.execute_reply":"2024-08-07T16:20:09.172781Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:20:15.044583Z","iopub.execute_input":"2024-08-07T16:20:15.045019Z","iopub.status.idle":"2024-08-07T16:20:15.060996Z","shell.execute_reply.started":"2024-08-07T16:20:15.044985Z","shell.execute_reply":"2024-08-07T16:20:15.059755Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1.0 / 255, horizontal_flip=True, zoom_range=0.1, shear_range=0.2, width_shift_range=0.1,\n    height_shift_range=0.1, rotation_range=4, vertical_flip=False\n)\n\nval_datagen = ImageDataGenerator(rescale=1.0 / 255)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:20:19.924741Z","iopub.execute_input":"2024-08-07T16:20:19.925762Z","iopub.status.idle":"2024-08-07T16:20:19.932307Z","shell.execute_reply.started":"2024-08-07T16:20:19.925721Z","shell.execute_reply":"2024-08-07T16:20:19.930843Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ntrain_generator = datagen.flow_from_directory(directory='/kaggle/working/train', target_size=(35, 35),\n                                              class_mode=\"categorical\", batch_size=batch_size, shuffle=True)\n\nval_generator = val_datagen.flow_from_directory(directory='/kaggle/working/val', target_size=(35, 35),\n                                                class_mode=\"categorical\", batch_size=batch_size, shuffle=True)\n\ntest_generator = val_datagen.flow_from_directory(directory='/kaggle/working/test', target_size=(35, 35),\n                                                 class_mode=\"categorical\", batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:20:27.941121Z","iopub.execute_input":"2024-08-07T16:20:27.942120Z","iopub.status.idle":"2024-08-07T16:20:28.573735Z","shell.execute_reply.started":"2024-08-07T16:20:27.942055Z","shell.execute_reply":"2024-08-07T16:20:28.572765Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 1993 images belonging to 3 classes.\nFound 855 images belonging to 3 classes.\nFound 1221 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit_generator(generator=train_generator, epochs=45, validation_data=val_generator, callbacks=[])","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:20:40.389274Z","iopub.execute_input":"2024-08-07T16:20:40.389903Z","iopub.status.idle":"2024-08-07T16:23:46.187577Z","shell.execute_reply.started":"2024-08-07T16:20:40.389856Z","shell.execute_reply":"2024-08-07T16:23:46.186475Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/45\n250/250 [==============================] - 13s 17ms/step - loss: 0.3963 - accuracy: 0.8635 - val_loss: 0.2367 - val_accuracy: 0.9146\nEpoch 2/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.2769 - accuracy: 0.9182 - val_loss: 0.2129 - val_accuracy: 0.9310\nEpoch 3/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.2281 - accuracy: 0.9313 - val_loss: 0.2097 - val_accuracy: 0.9298\nEpoch 4/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.2247 - accuracy: 0.9373 - val_loss: 0.1941 - val_accuracy: 0.9357\nEpoch 5/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.2036 - accuracy: 0.9393 - val_loss: 0.1868 - val_accuracy: 0.9368\nEpoch 6/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.2079 - accuracy: 0.9313 - val_loss: 0.1776 - val_accuracy: 0.9439\nEpoch 7/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.2025 - accuracy: 0.9378 - val_loss: 0.1784 - val_accuracy: 0.9368\nEpoch 8/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.2019 - accuracy: 0.9453 - val_loss: 0.1726 - val_accuracy: 0.9427\nEpoch 9/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1954 - accuracy: 0.9368 - val_loss: 0.1588 - val_accuracy: 0.9404\nEpoch 10/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1911 - accuracy: 0.9358 - val_loss: 0.1675 - val_accuracy: 0.9462\nEpoch 11/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1853 - accuracy: 0.9413 - val_loss: 0.2185 - val_accuracy: 0.9146\nEpoch 12/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.2049 - accuracy: 0.9353 - val_loss: 0.1902 - val_accuracy: 0.9333\nEpoch 13/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1887 - accuracy: 0.9368 - val_loss: 0.1751 - val_accuracy: 0.9368\nEpoch 14/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1838 - accuracy: 0.9398 - val_loss: 0.1810 - val_accuracy: 0.9474\nEpoch 15/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1625 - accuracy: 0.9448 - val_loss: 0.1537 - val_accuracy: 0.9404\nEpoch 16/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1664 - accuracy: 0.9483 - val_loss: 0.1531 - val_accuracy: 0.9439\nEpoch 17/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1785 - accuracy: 0.9408 - val_loss: 0.1614 - val_accuracy: 0.9380\nEpoch 18/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1679 - accuracy: 0.9478 - val_loss: 0.1499 - val_accuracy: 0.9450\nEpoch 19/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1547 - accuracy: 0.9483 - val_loss: 0.1573 - val_accuracy: 0.9497\nEpoch 20/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1527 - accuracy: 0.9488 - val_loss: 0.1828 - val_accuracy: 0.9322\nEpoch 21/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1577 - accuracy: 0.9443 - val_loss: 0.1766 - val_accuracy: 0.9404\nEpoch 22/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1398 - accuracy: 0.9533 - val_loss: 0.1415 - val_accuracy: 0.9497\nEpoch 23/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1579 - accuracy: 0.9473 - val_loss: 0.1411 - val_accuracy: 0.9520\nEpoch 24/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1419 - accuracy: 0.9493 - val_loss: 0.1599 - val_accuracy: 0.9462\nEpoch 25/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1460 - accuracy: 0.9538 - val_loss: 0.1583 - val_accuracy: 0.9404\nEpoch 26/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1435 - accuracy: 0.9503 - val_loss: 0.1390 - val_accuracy: 0.9497\nEpoch 27/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1452 - accuracy: 0.9483 - val_loss: 0.1335 - val_accuracy: 0.9544\nEpoch 28/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1448 - accuracy: 0.9498 - val_loss: 0.1635 - val_accuracy: 0.9474\nEpoch 29/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1336 - accuracy: 0.9543 - val_loss: 0.1666 - val_accuracy: 0.9485\nEpoch 30/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1311 - accuracy: 0.9538 - val_loss: 0.1436 - val_accuracy: 0.9474\nEpoch 31/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1276 - accuracy: 0.9483 - val_loss: 0.1460 - val_accuracy: 0.9485\nEpoch 32/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1322 - accuracy: 0.9528 - val_loss: 0.1490 - val_accuracy: 0.9474\nEpoch 33/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1113 - accuracy: 0.9574 - val_loss: 0.1579 - val_accuracy: 0.9544\nEpoch 34/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1365 - accuracy: 0.9533 - val_loss: 0.1439 - val_accuracy: 0.9520\nEpoch 35/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1230 - accuracy: 0.9568 - val_loss: 0.1530 - val_accuracy: 0.9462\nEpoch 36/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1090 - accuracy: 0.9634 - val_loss: 0.1573 - val_accuracy: 0.9509\nEpoch 37/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1259 - accuracy: 0.9558 - val_loss: 0.1510 - val_accuracy: 0.9579\nEpoch 38/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1033 - accuracy: 0.9679 - val_loss: 0.1559 - val_accuracy: 0.9485\nEpoch 39/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1180 - accuracy: 0.9584 - val_loss: 0.1601 - val_accuracy: 0.9520\nEpoch 40/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.0964 - accuracy: 0.9644 - val_loss: 0.1604 - val_accuracy: 0.9520\nEpoch 41/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1242 - accuracy: 0.9599 - val_loss: 0.1404 - val_accuracy: 0.9544\nEpoch 42/45\n250/250 [==============================] - 4s 15ms/step - loss: 0.1134 - accuracy: 0.9604 - val_loss: 0.1617 - val_accuracy: 0.9520\nEpoch 43/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.1218 - accuracy: 0.9589 - val_loss: 0.1447 - val_accuracy: 0.9532\nEpoch 44/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.0969 - accuracy: 0.9629 - val_loss: 0.1681 - val_accuracy: 0.9474\nEpoch 45/45\n250/250 [==============================] - 4s 16ms/step - loss: 0.0967 - accuracy: 0.9639 - val_loss: 0.2022 - val_accuracy: 0.9439\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7a976aaba6d0>"},"metadata":{}}]},{"cell_type":"code","source":"model_loss, model_acc = model.evaluate(test_generator)\nprint(f'Test Loss: {model_loss}, Test Accuracy: {model_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:23:50.139810Z","iopub.execute_input":"2024-08-07T16:23:50.140278Z","iopub.status.idle":"2024-08-07T16:23:51.341064Z","shell.execute_reply.started":"2024-08-07T16:23:50.140239Z","shell.execute_reply":"2024-08-07T16:23:51.339929Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"153/153 [==============================] - 1s 7ms/step - loss: 0.2140 - accuracy: 0.9509\nTest Loss: 0.21403174102306366, Test Accuracy: 0.9508599638938904\n","output_type":"stream"}]}]}